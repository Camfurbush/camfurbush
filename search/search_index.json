{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Camfurbush","text":"<p>My name is Cameron Furbush. I have experience working as a Site Reliability Engineer/Platform Engineer in both large and small companies. I received a Bachelor's degree in Information Technology from the University of West Florida. I love to travel, exercise, and learn new hobbies!</p> <p></p>"},{"location":"docs/learning-material/","title":"Learning Material","text":"<p>This page is to note down any useful learning material I've found useful for life in tech</p>"},{"location":"docs/learning-material/#sre","title":"SRE","text":"<ul> <li>SRE Handbook</li> <li>Practice of Cloud Systems Adminstration</li> </ul>"},{"location":"docs/learning-material/#management","title":"Management","text":"<ul> <li>Time Managment for Systems Administrators</li> <li>An Elegant Puzzle</li> <li>Staff Engineer's handbook</li> <li>The Managers Path</li> </ul>"},{"location":"docs/learning-material/#application-development","title":"Application Development","text":"<ul> <li>Clean Architecture</li> <li>Pragmatic Programmer</li> </ul>"},{"location":"docs/learning-material/#random","title":"Random","text":"<ul> <li>https://github.com/keyvanakbary/learning-notes/tree/master</li> <li>https://github.com/shospodarets/awesome-platform-engineering</li> </ul>"},{"location":"docs/yadm/","title":"What is YADM?","text":"<p>YADM stands for Yet Another Dotfiles Manager, this allows you to track dotfiles using git. Once you run <code>yadm clone</code> locally, this will automatically distribute your dotfiles on your machine and update them with any changes.</p>"},{"location":"docs/yadm/#setup","title":"Setup","text":"<ol> <li> <p>Install yadm</p> <p><code>sh apt update apt install yadm</code></p> <p>or</p> <p><code>sh brew install yadm</code></p> </li> <li> <p>Clone the repo using yadm</p> <p><code>sh yadm clone git@github.com:Camfurbush/dotfiles.git</code></p> </li> <li> <p>Update when needed</p> <p><code>sh yadm pull origin main</code></p> </li> </ol>"},{"location":"docs/yadm/#troubleshooting","title":"Troubleshooting","text":"<ol> <li> <p>How to encrypt files</p> <p><code>sh export GPG_TTY=$(tty) # Add this to your ~/.bashrc yadm encrypt</code></p> </li> <li> <p>How to add files using yadm</p> <p><code>sh yadm add ~/.config/yadm/files.gpg yadm commit -m \"add encrypted files\" yadm push origin HEAD:main</code></p> </li> <li> <p>How to update files locally</p> <p><code>sh yadm pull origin main</code></p> </li> </ol>"},{"location":"docs/interview-questions/ansible/ansible/","title":"Ansible","text":""},{"location":"docs/interview-questions/ansible/ansible/#how-does-ansible-work","title":"How does Ansible work?","text":"<ul> <li>Ansible is a combination of multiple pieces working together to become an automation tool. Mainly these are modules, playbooks, and plugins.</li> <li>Modules are small codes that will get executed. There are multiple inbuilt modules that serve as a starting point for building tasks.</li> <li>Playbooks contain plays which further is a group of tasks. This is the place to define the workflow or the steps needed to complete a process</li> <li>Plugins are special kinds of modules that run on the main control machine for logging purposes. There are other types of plugins also.</li> </ul>"},{"location":"docs/interview-questions/docker/docker/","title":"Docker","text":""},{"location":"docs/interview-questions/docker/docker/#what-is-docker","title":"What is Docker?","text":"<ul> <li>Docker is a containerization platform which packages your application and all its dependencies together in the form of containers so as to ensure that your application works seamlessly in any environment be it development or test or production.</li> <li>Docker containers, wrap a piece of software in a complete filesystem that contains everything needed to run: code, runtime, system tools, system libraries etc. anything that can be installed on a server.</li> <li>This guarantees that the software will always run the same, regardless of its environment.</li> </ul>"},{"location":"docs/interview-questions/docker/docker/#what-are-docker-images","title":"What are docker images?","text":"<p>They are executable packages(bundled with application code &amp; dependencies, software packages, etc.) for the purpose of creating containers. Docker images can be deployed to any docker environment and the containers can be spun up there to run the application.</p>"},{"location":"docs/interview-questions/docker/docker/#what-can-you-tell-about-docker-compose","title":"What can you tell about Docker Compose?","text":"<ul> <li>It is a YAML file consisting of all the details regarding various services, networks, and volumes that are needed for setting up the Docker-based application. So, docker-compose is used for creating multiple containers, host them and establish communication between them. For the purpose of communication amongst the containers, ports are exposed by each and every container.</li> </ul>"},{"location":"docs/interview-questions/docker/docker/#differentiate-between-copy-and-add-commands-that-are-used-in-a-dockerfile","title":"Differentiate between COPY and ADD commands that are used in a Dockerfile?","text":"<ul> <li>Both the commands have similar functionality, but COPY is more preferred because of its higher transparency level than that of ADD.</li> <li>COPY provides just the basic support of copying local files into the container whereas ADD provides additional features like remote URL and tar extraction support.</li> </ul>"},{"location":"docs/interview-questions/docker/docker/#can-you-explain-the-difference-between-cmd-and-entrypoint","title":"Can you explain the difference between CMD and ENTRYPOINT?","text":"<ul> <li>CMD command provides executable defaults for an executing container. In case the executable has to be omitted then the usage of ENTRYPOINT instruction along with the JSON array format has to be incorporated.</li> <li>ENTRYPOINT specifies that the instruction within it will always be run when the container starts.</li> <li>This command provides an option to configure the parameters and the executables. If the DockerFile does not have this command, then it would still get inherited from the base image mentioned in the FROM instruction.</li> <li>The most commonly used ENTRYPOINT is /bin/sh or /bin/bash for most of the base images.</li> <li>As part of good practices, every DockerFile should have at least one of these two commands</li> </ul>"},{"location":"docs/interview-questions/docker/docker/#how-would-you-download-a-remote-docker-image-to-your-machine","title":"How would you download a remote docker image to your machine","text":"<ul> <li><code>docker pull &lt;image_name&gt;</code></li> </ul>"},{"location":"docs/interview-questions/docker/docker/#how-do-you-create-a-docker-container-from-an-image","title":"How do you create a docker container from an image?","text":"<ul> <li><code>docker run -it -d &lt;image_name&gt;</code></li> </ul>"},{"location":"docs/interview-questions/docker/docker/#how-would-you-connect-to-a-running-container","title":"How would you connect to a running container","text":"<ul> <li><code>docker exec -it &lt;container id&gt; bash</code></li> </ul>"},{"location":"docs/interview-questions/docker/docker/#how-do-you-list-all-running-docker-images","title":"How do you list all running docker images","text":"<ul> <li><code>docker ps</code></li> </ul>"},{"location":"docs/interview-questions/docker/docker/#how-would-you-build-and-deploy-a-custom-docker-image","title":"How would you build and deploy a custom docker image","text":"<ul> <li>Open a terminal in the same folder as your Dockerfile</li> </ul> <pre><code>docker login\ndocker build .\ndocker images # get the id of the docker image\ndocker tag IMAGE_ID NEW_IMAGE_NAME:latest\ndocker push NEW_IMAGE_NAME:latest\n</code></pre>"},{"location":"docs/interview-questions/docker/docker/#dockerfile","title":"Dockerfile","text":"<ul> <li>Know the components of a Dockerfile and how to make your own</li> <li>This uses the ubuntu docker image and installs python and an python app</li> </ul> <pre><code>FROM ubuntu\nRUN apt-get update &amp;&amp; apt-get install curl python\nCOPY main.py /app/main.py\nWORKDIR /app\nENTRYPOINT [\"python /app/main.py\"]\n</code></pre>"},{"location":"docs/interview-questions/docker/docker/#how-do-you-keep-docker-images-lightweight","title":"How do you keep docker images lightweight?","text":"<ul> <li>Disable caching in commands</li> <li>Reduce the amount of layers</li> <li>Use multi-stage builds</li> <li>Run multiple commands on the same line</li> </ul>"},{"location":"docs/interview-questions/docker/docker/#what-is-a-multi-stage-docker-build-and-whats-the-benefit","title":"What is a multi-stage docker build and whats the benefit?","text":"<ul> <li>A multi-stage docker build is a technique used to keep dockerfiles small.</li> <li>An example, use a dockerfile to build the application, then copy the compiled application and place on a lightweight image like alpine to serve the compiled app.</li> </ul> <pre><code># syntax=docker/dockerfile:1\n\nFROM golang:1.16 AS builder\nWORKDIR /go/src/github.com/alexellis/href-counter/\nRUN go get -d -v golang.org/x/net/html\nCOPY app.go ./\nRUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .\n\nFROM alpine:latest\nRUN apk --no-cache add ca-certificates\nWORKDIR /root/\nCOPY --from=builder /go/src/github.com/alexellis/href-counter/app ./\nCMD [\"./app\"]\n</code></pre>"},{"location":"docs/interview-questions/docker/scenarios/","title":"Docker","text":"<p>This section covers some scenarios for working with Docker</p>"},{"location":"docs/interview-questions/docker/scenarios/#what-are-the-main-parts-of-a-dockerfile","title":"What are the main parts of a Dockerfile","text":"<ol> <li>The <code>FROM</code> section determines what docker image to use as a base</li> </ol>"},{"location":"docs/interview-questions/docker/scenarios/#walk-through-how-you-would-build-and-push-a-docker-image","title":"Walk through how you would build and push a Docker Image","text":"<ol> <li>Open a terminal in the directory that has the Dockerfile</li> <li>Run <code>docker build .</code> to build the Dockerfile in the current directory</li> <li>After the docker image has been built successfully, you need to tag it</li> <li>Run <code>docker ps</code> to get the image name of the docker image that was just build</li> <li>Run <code>docker tag IMAGE_ID DOCKER_REGISTRY.COM/IMAGE_NAME_YOU_WANT</code></li> <li>Then run <code>docker push IMAGE_NAME_YOU_WANT</code> to push the docker image to the registry</li> </ol> <p>https://stackoverflow.com/questions/28349392/how-to-push-a-docker-image-to-a-private-repository</p>"},{"location":"docs/interview-questions/docker/scenarios/#describe-how-you-would-try-to-make-the-image-size-smaller","title":"Describe how you would try to make the image size smaller","text":"<ol> <li>Docker images are typically large because they are comprised of multiple layers</li> <li> <p>You can try to chain commands together to reduce the number of layers</p> <p><code>Dockerfile RUN apt update RUN apt -y install curl RUN apt -y install python3 RUN apt -y install vim</code></p> <p>= 4 layers vs <code>RUN apt update &amp;&amp; apt -y install curl python3 vim</code> = 1 layer</p> </li> <li> <p>Another option is to use multi-stage builds</p> </li> </ol>"},{"location":"docs/interview-questions/docker/scenarios/#can-you-describe-how-multi-stage-builds-work-and-how-to-implement-it","title":"Can you describe how multi-stage builds work and how to implement it?","text":"<ol> <li> <p>Multi-stage builds work by having a \"builder\" docker image that downloads all the dependencies for an app, then builds the binary for the application. Then the binary can be copied to a more lightweight image without the build dependencies and can serve the application, resulting in a smaller image</p> </li> <li> <p>You would setup a Dockerfile as normal to compile the application. You would define the <code>FROM</code> section as <code>FROM IMAGE AS builder</code> to notate its the builder image. Further down you would define the image to serve the binary and add a step to <code>COPY APP_NAME --from=builder</code> to show to copy that file to the new image.</p> </li> </ol> <p>See example Dockerfiles in this repo for more</p>"},{"location":"docs/interview-questions/kubernetes/control-plane/","title":"Control Plane","text":""},{"location":"docs/interview-questions/kubernetes/control-plane/#what-are-the-main-components-of-a-kubernetes-cluster","title":"What are the main components of a Kubernetes cluster?","text":""},{"location":"docs/interview-questions/kubernetes/control-plane/#master-node","title":"Master Node","text":"<ul> <li> <p>ETCD   Stores the configuration details and essential values.</p> </li> <li> <p>Scheduler   Assigns tasks to the worker nodes.</p> </li> <li> <p>API Server </p> </li> <li>Performs all operations on the cluster.  </li> <li> <p>Acts as a central management entity that receives all REST requests for modifications, serving as a frontend to the cluster.</p> </li> <li> <p>Controller Manager(s)   Includes:  </p> </li> <li>Endpoints controller  </li> <li>Service accounts controller  </li> <li>Namespace controller  </li> <li>Node controller  </li> <li>Token controller  </li> <li>Replication controller  </li> </ul>"},{"location":"docs/interview-questions/kubernetes/control-plane/#worker-node","title":"Worker Node","text":"<ul> <li>Pod </li> <li> <p>A pod is one or more containers controlled as a single application.</p> </li> <li> <p>Container Runtime </p> </li> <li>Runs applications in an isolated, lightweight operating environment.  </li> <li> <p>Responsible for pulling and running containers from Docker images.</p> </li> <li> <p>Kubelet </p> </li> <li>Conveys information to and from the control plane service.  </li> <li> <p>Maintains the work status and the node server.</p> </li> <li> <p>Kube Proxy </p> </li> <li>Acts as a load balancer and network proxy for services on a single worker node.  </li> <li>Manages pods, volumes, secrets, container creation, health checks, etc.  </li> <li>Runs on every node to make services available to external hosts.</li> </ul>"},{"location":"docs/interview-questions/kubernetes/deployments/","title":"Deployments","text":""},{"location":"docs/interview-questions/kubernetes/deployments/#what-is-a-pod-in-kubernetes","title":"What is a pod in Kubernetes?","text":"<ul> <li>In this Kubernetes interview question, try giving a thorough answer instead of a one-liner.</li> <li>Pods are high-level structures that wrap one or more containers. This is because containers are not run directly in Kubernetes.</li> <li>Containers in the same pod share a local network and the same resources, allowing them to easily communicate with other containers in the same pod as if they were on the same machine while at the same time maintaining a degree of isolation.</li> </ul>"},{"location":"docs/interview-questions/kubernetes/deployments/#what-are-daemon-sets","title":"What are Daemon sets?","text":"<p>A Daemon set is a set of pods that runs only once on a host. They are used for host layer attributes like a network or for monitoring a network, which you may not need to run on a host more than once.</p>"},{"location":"docs/interview-questions/kubernetes/deployments/#how-do-we-control-the-resource-usage-of-pod","title":"How do we control the resource usage of Pod?","text":"<p>With the use of limit and request resource usage of a POD can be controlled.</p>"},{"location":"docs/interview-questions/kubernetes/kubernetes/","title":"Kubernetes","text":"<ul> <li>Kubernetes</li> <li>What is Docker?</li> <li>What is Kubernetes?</li> <li>How are Kubernetes and Docker related</li> <li>What is Minikube?</li> <li>Guides</li> </ul>"},{"location":"docs/interview-questions/kubernetes/kubernetes/#what-is-docker","title":"What is Docker?","text":"<ul> <li>Docker is an open-source platform that allows developers to automate the deployment of applications inside lightweight, portable containers. It ensures that the application runs consistently across different environments.</li> </ul>"},{"location":"docs/interview-questions/kubernetes/kubernetes/#what-is-kubernetes","title":"What is Kubernetes?","text":"<ul> <li>Kubernetes is an open-source container orchestration platform that automates the deployment, scaling, and management of containerized applications. It helps manage clusters of containers at scale.</li> </ul>"},{"location":"docs/interview-questions/kubernetes/kubernetes/#how-are-kubernetes-and-docker-related","title":"How are Kubernetes and Docker related","text":"<ul> <li>Docker is an open-source platform/runtime utilizing cgroups to run software in a containerized environment. Its main benefit is that it packages the settings and dependencies that the software/application needs to run into a container, which allows for portability and several other advantages.</li> <li>Kubernetes allows for the orchestration and deployment of containers. Kubernetes is typically run on a cluster</li> </ul>"},{"location":"docs/interview-questions/kubernetes/kubernetes/#what-is-minikube","title":"What is Minikube?","text":"<ul> <li>Software that allows you to run a single instance of Kubernetes locally. This allows you to deploy to your local cluster before deploying to a real cluster</li> </ul>"},{"location":"docs/interview-questions/kubernetes/kubernetes/#guides","title":"Guides","text":"<ul> <li>https://www.simplilearn.com/tutorials/kubernetes-tutorial?source=sl_frs_nav_playlist_video_clicked</li> <li>https://kubernetes.io/docs/tasks/debug/debug-application/debug-pods/</li> <li>https://kubernetes.io/docs/reference/kubectl/cheatsheet/</li> </ul>"},{"location":"docs/interview-questions/kubernetes/networking/","title":"Networking","text":""},{"location":"docs/interview-questions/kubernetes/networking/#what-are-the-key-components-of-kubernetes-networking","title":"What are the key components of Kubernetes networking?","text":"<ul> <li>Pod-to-Pod Communication: Ensures all pods can communicate with each other without NAT.  </li> <li>Service Discovery: Uses DNS to allow pods to discover services.  </li> <li>Ingress and Egress Traffic: Manages traffic entering and leaving the cluster.  </li> <li>Network Policies: Controls traffic flow between pods and external endpoints.</li> </ul>"},{"location":"docs/interview-questions/kubernetes/networking/#what-is-an-ingress","title":"What is an Ingress?","text":"<ul> <li>Ingress is a collection of routing rules that decide how the external services access the services running inside a Kubernetes cluster.</li> <li>Ingress provides load balancing, SSL termination, and name-based virtual hosting.</li> </ul>"},{"location":"docs/interview-questions/kubernetes/networking/#what-is-a-service-in-kubernetes","title":"What is a Service in Kubernetes?","text":"<ul> <li>A Service is an abstraction that defines a logical set of pods and a policy to access them.  </li> <li>It provides stable networking for pods, even if the underlying pods are replaced.  </li> <li>Types of Services:  </li> <li>ClusterIP: Exposes the service on an internal IP within the cluster.  </li> <li>NodePort: Exposes the service on a static port on each node.  </li> <li>LoadBalancer: Exposes the service externally using a cloud provider's load balancer.  </li> <li>ExternalName: Maps the service to an external DNS name.</li> </ul>"},{"location":"docs/interview-questions/kubernetes/networking/#what-is-a-network-policy","title":"What is a Network Policy?","text":"<ul> <li>A Network Policy is a specification of how pods are allowed to communicate with each other and other network endpoints.  </li> <li>It uses labels to select pods and define rules for ingress and egress traffic.  </li> <li>Network policies are implemented by network plugins like Calico, Cilium, or Weave.</li> </ul>"},{"location":"docs/interview-questions/kubernetes/networking/#how-does-kubernetes-handle-dns-resolution","title":"How does Kubernetes handle DNS resolution?","text":"<ul> <li>Kubernetes uses a DNS add-on (e.g., CoreDNS) to provide DNS resolution for services and pods.  </li> <li>Each service gets a DNS entry in the format <code>&lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local</code>.  </li> <li>Pods can resolve services by their DNS names, enabling communication without hardcoding IP addresses.</li> </ul>"},{"location":"docs/interview-questions/kubernetes/networking/#how-does-kubernetes-manage-external-traffic-to-services","title":"How does Kubernetes manage external traffic to services?","text":"<ul> <li>Kubernetes uses an Ingress Controller or LoadBalancer service type to manage external traffic.  </li> <li>Ingress Controllers (e.g., NGINX, Traefik) handle HTTP/HTTPS traffic and provide routing, SSL termination, and host-based routing.  </li> <li>LoadBalancer services rely on cloud provider integrations to expose services externally.</li> </ul>"},{"location":"docs/interview-questions/kubernetes/node/","title":"Nodes","text":""},{"location":"docs/interview-questions/kubernetes/node/#what-is-a-node-in-kubernetes","title":"What is a node in Kubernetes?","text":"<ul> <li>A node is the smallest fundamental unit of computing hardware.</li> <li>It represents a single machine in a cluster, which could be a physical machine in a data center or a virtual machine from a cloud provider.</li> <li>Each machine can substitute any other machine in a Kubernetes cluster.</li> <li>The master in Kubernetes controls the nodes that have containers.</li> </ul>"},{"location":"docs/interview-questions/kubernetes/troubleshooting/","title":"Troubleshooting","text":""},{"location":"docs/interview-questions/kubernetes/troubleshooting/#a-developer-has-a-pod-that-wont-deployupdatework-how-would-you-troubleshoot-it","title":"A developer has a pod that won't deploy/update/work, how would you troubleshoot it?","text":"<ul> <li>Run <code>kubectl get pods -n $namespace</code> to investigate the error to determine if there's an error message</li> <li>Make sure the pod is running, there isn't a <code>CrashLoopBackoff</code>, <code>ImagePullErr</code>, etc</li> </ul>"},{"location":"docs/interview-questions/kubernetes/troubleshooting/#how-do-you-get-all-your-running-pods","title":"How do you get all your running pods?","text":"<ul> <li><code>kubectl get pods -A</code></li> </ul>"},{"location":"docs/interview-questions/kubernetes/troubleshooting/#how-to-tell-why-a-container-is-failing","title":"How to tell why a container is failing?","text":"<ul> <li><code>kubectl describe pod $pod_name</code>, investigate the error or events</li> <li><code>kubectl logs $pod</code></li> </ul>"},{"location":"docs/interview-questions/kubernetes/troubleshooting/#how-do-you-check-the-logs-of-a-specific-container-in-a-pod","title":"How do you check the logs of a specific container in a pod?","text":"<ul> <li>Use <code>kubectl logs $pod_name -c $container_name</code> to view logs for a specific container in a multi-container pod.</li> </ul>"},{"location":"docs/interview-questions/kubernetes/troubleshooting/#how-do-you-troubleshoot-a-service-that-is-not-reachable","title":"How do you troubleshoot a service that is not reachable?","text":"<ul> <li>Run <code>kubectl get svc</code> to ensure the service is created and has a valid ClusterIP or external IP.</li> <li>Use <code>kubectl describe svc $service_name</code> to check for configuration issues.</li> <li>Verify that the pods backing the service are running and reachable.</li> <li>Verify that the pods and services are using the proper labels/selectors</li> </ul>"},{"location":"docs/interview-questions/kubernetes/troubleshooting/#how-do-you-debug-a-pod-stuck-in-imagepullbackoff","title":"How do you debug a pod stuck in <code>ImagePullBackOff</code>?","text":"<ul> <li>Run <code>kubectl describe pod $pod_name</code> to verify the image name and tag are correct.</li> <li>Ensure the image is accessible from the container registry and that proper credentials are configured if needed.</li> </ul>"},{"location":"docs/interview-questions/kubernetes/troubleshooting/#how-do-you-check-resource-usage-for-a-pod","title":"How do you check resource usage for a pod?","text":"<ul> <li>Use <code>kubectl top pod $pod_name</code> to view CPU and memory usage.</li> <li>Ensure the pod is not exceeding its resource limits defined in the deployment or pod specification.</li> </ul>"},{"location":"docs/interview-questions/kubernetes/troubleshooting/#how-do-you-troubleshoot-dns-issues-in-a-pod","title":"How do you troubleshoot DNS issues in a pod?","text":"<ul> <li>Use <code>kubectl exec -it $pod_name -- nslookup $service_name</code> to test DNS resolution.</li> <li>Verify that the <code>kube-dns</code> or <code>CoreDNS</code> pod is running and healthy using <code>kubectl get pods -n kube-system</code>.</li> </ul>"},{"location":"docs/interview-questions/linux/linux/","title":"Linux","text":"<ul> <li>Linux</li> <li>What is a \u201c/proc\u201d file system?</li> <li>What is a Zombie Process?</li> <li>What is the load average?</li> <li>Commands<ul> <li>How do you view the files in the current directory?</li> <li>How do you view the current kernel version?</li> <li>How do you view the current running processes?</li> <li>Where are common log files located?</li> <li>How do you view available memory?</li> <li>How do you view current CPU load?</li> <li>How do you view current disk usage</li> </ul> </li> <li>Scenario Based Questions</li> </ul>"},{"location":"docs/interview-questions/linux/linux/#what-is-a-proc-file-system","title":"What is a \u201c/proc\u201d file system?","text":"<ul> <li>Proc file system is a pseudo or virtual file system that provides an interface to the kernel data structure. It generally includes useful information about processes that are running currently. It can also be used to change some kernel parameters at runtime or during execution. It is also regarded as a control and information center for the kernel. All files under this directory are named virtual files</li> </ul>"},{"location":"docs/interview-questions/linux/linux/#what-is-a-zombie-process","title":"What is a Zombie Process?","text":"<ul> <li>Zombie Process, also referred to as a defunct or dead process in Linux, is a process that has finished the execution, but its entry remains in the process table. It usually happens due to a lack of correspondence between parent and child processes.</li> </ul>"},{"location":"docs/interview-questions/linux/linux/#what-is-the-load-average","title":"What is the load average?","text":"<ul> <li>As the name suggests, is the average system load on Linux servers being calculated over a given period of time. The load average of Linux servers can be found using \u201ctop\u201d and \u201cuptime\u201d commands. It is simply used to keep track of system resources. It is represented by a decimal number starting at 0.00. It tells you the load that the system has been under.</li> <li>This should be at roughly 1.0 per CPU.</li> </ul>"},{"location":"docs/interview-questions/linux/linux/#commands","title":"Commands","text":""},{"location":"docs/interview-questions/linux/linux/#how-do-you-view-the-files-in-the-current-directory","title":"How do you view the files in the current directory?","text":"<ul> <li><code>ls</code></li> </ul>"},{"location":"docs/interview-questions/linux/linux/#how-do-you-view-the-current-kernel-version","title":"How do you view the current kernel version?","text":"<ul> <li><code>uname -a</code></li> </ul>"},{"location":"docs/interview-questions/linux/linux/#how-do-you-view-the-current-running-processes","title":"How do you view the current running processes?","text":"<ul> <li>ps aux</li> </ul>"},{"location":"docs/interview-questions/linux/linux/#where-are-common-log-files-located","title":"Where are common log files located?","text":"<ul> <li>/var/log</li> </ul>"},{"location":"docs/interview-questions/linux/linux/#how-do-you-view-available-memory","title":"How do you view available memory?","text":"<ul> <li><code>free</code></li> <li><code>top</code></li> </ul>"},{"location":"docs/interview-questions/linux/linux/#how-do-you-view-current-cpu-load","title":"How do you view current CPU load?","text":"<ul> <li><code>top</code></li> </ul>"},{"location":"docs/interview-questions/linux/linux/#how-do-you-view-current-disk-usage","title":"How do you view current disk usage","text":"<ul> <li>df -h</li> <li>pvdisplay</li> <li>lvdisplay</li> <li>lsblk</li> </ul>"},{"location":"docs/interview-questions/linux/linux/#scenario-based-questions","title":"Scenario Based Questions","text":"<ul> <li>Sometimes they will ask scenario based questions like:</li> <li>A developer tells you the app server is reporting a 503, how do you investigate</li> <li>Walk through how to resolve it<ul> <li>SSH to the server</li> <li>Use systemctl to check the service</li> <li>Check the application logs</li> <li>Investigate error messages</li> <li>etc</li> </ul> </li> <li>Be comfortable navigating around linux</li> </ul>"},{"location":"docs/interview-questions/sre/sre/","title":"SRE Interview Questions","text":"<p>This page covers some different questions and categories an SRE might be expected to know</p> <ul> <li>SRE Interview Questions</li> <li>How and why would you use error budgets?</li> <li>Explain Blue-Green Deployment Technique</li> <li>What are some common deployment strategies?<ul> <li>Blue/Green</li> <li>Canary</li> <li>Rolling</li> </ul> </li> <li>What is an SLA/SLI/SLO and how do they relate to each other</li> <li>What are the differences between continuous integration, continuous delivery, and continuous deployment</li> <li>What is the difference between pull-based and push-based configuration management architecture</li> <li>Can you explain is impotency is or what it means when something is idempotent</li> <li>What is immutability</li> <li>Recommended Resources<ul> <li>Courses</li> <li>Articles</li> <li>Books</li> </ul> </li> <li>References</li> </ul>"},{"location":"docs/interview-questions/sre/sre/#how-and-why-would-you-use-error-budgets","title":"How and why would you use error budgets?","text":"<ul> <li>An error budget is the amount of acceptable unreliability a service can have before customer happiness is impacted.</li> <li>If a service is well within its budget, the developers can take more risks in their releases.</li> <li>If not, developers need to make safer choices.</li> </ul>"},{"location":"docs/interview-questions/sre/sre/#explain-blue-green-deployment-technique","title":"Explain Blue-Green Deployment Technique","text":"<ul> <li>Blue-green deployment is a technique that reduces downtime and risk by running two identical production environments called Blue and Green. At any time, only one of the environments is live, with the live environment serving all production traffic. For this example, Blue is currently live and Green is idle.</li> <li>As you prepare a new version of your software, deployment and the final stage of testing takes place in the environment that is not live: in this example, Green. Once you have deployed and fully tested the software in Green, you switch the router so all incoming requests now go to Green instead of Blue. Green is now live, and Blue is idle.</li> <li>This technique can eliminate downtime due to application deployment. In addition, blue-green deployment reduces risk: if something unexpected happens with your new version on Green, you can immediately roll back to the last version by switching back to Blue.</li> </ul>"},{"location":"docs/interview-questions/sre/sre/#what-are-some-common-deployment-strategies","title":"What are some common deployment strategies?","text":""},{"location":"docs/interview-questions/sre/sre/#bluegreen","title":"Blue/Green","text":"<ul> <li>Blue-green deployments are a pattern whereby we reduce downtime during production deployments by having two separate production environments (\"blue\" and \"green\").</li> </ul>"},{"location":"docs/interview-questions/sre/sre/#canary","title":"Canary","text":"<ul> <li>Canary deployments are a pattern for rolling out releases to a subset of users or servers.</li> <li>The idea is to first deploy the change to a small subset of servers, test it, and then roll the change out to the rest of the servers.</li> <li>The canary deployment serves as an early warning indicator with less impact on downtime: if the canary deployment fails, the rest of the servers aren't impacted.</li> </ul>"},{"location":"docs/interview-questions/sre/sre/#rolling","title":"Rolling","text":"<ul> <li>Rolling deployments are a pattern whereby, instead of deploying a package to all servers at once, we slowly roll out the release by deploying it to each server one-by-one.</li> <li>In load balanced scenarios, this allows us to reduce overall downtime.</li> </ul>"},{"location":"docs/interview-questions/sre/sre/#what-is-an-slaslislo-and-how-do-they-relate-to-each-other","title":"What is an SLA/SLI/SLO and how do they relate to each other","text":"<ul> <li>An SLA (service level agreement) is an agreement between provider and client about measurable metrics like uptime, responsiveness, and responsibilities.</li> <li>An SLO (service level objective) is an agreement within an SLA about a specific metric like uptime or response time</li> <li>An SLI (service level indicator) measures compliance with an SLO (service level objective).   </li> </ul>"},{"location":"docs/interview-questions/sre/sre/#what-are-the-differences-between-continuous-integration-continuous-delivery-and-continuous-deployment","title":"What are the differences between continuous integration, continuous delivery, and continuous deployment","text":"<ul> <li>Developers practicing continuous integration merge their changes back to the main branch as often as possible. By doing so, you avoid the integration hell that usually happens when people wait for release day to merge their changes into the release branch.</li> <li>Continuous delivery is an extension of continuous integration to make sure that you can release new changes to your customers quickly in a sustainable way. This means that on top of having automated your testing, you also have automated your release process and you can deploy your application at any point of time by clicking on a button.</li> <li>Continuous deployment goes one step further than continuous delivery. With this practice, every change that passes all stages of your production pipeline is released to your customers. There's no human intervention, and only a failed test will prevent a new change to be deployed to production</li> </ul>"},{"location":"docs/interview-questions/sre/sre/#what-is-the-difference-between-pull-based-and-push-based-configuration-management-architecture","title":"What is the difference between pull-based and push-based configuration management architecture","text":"<ul> <li>Pull Model: The nodes are dynamically updated by pulling the latest configuration from a centralized server.</li> <li>Push Model: Centralized server pushes the configurations to the nodes</li> </ul>"},{"location":"docs/interview-questions/sre/sre/#can-you-explain-is-impotency-is-or-what-it-means-when-something-is-idempotent","title":"Can you explain is impotency is or what it means when something is idempotent","text":"<ul> <li> <p>The term impotency means that when changes are applied multiple times, the state is mutated (changed) just once. First, it already assumes that there are going to be changes applied which means that you cannot have something both immutable and have idempotent actions done to it (no actions are done to it by contract).</p> </li> <li> <p>In the use of configuration management tools, impotency is used in some cases when applying the same change multiple times. Like adding the line that says localhost to the /etc/hosts file, you don't really need multiple such lines and if one already exists it is safe to not try to append again.</p> </li> </ul>"},{"location":"docs/interview-questions/sre/sre/#what-is-immutability","title":"What is immutability","text":"<ul> <li>Immutability, which literally means \"no mutations\" or \"no changes\". In the DevOps sense, it means that once you created an artifact, be that a container image, or a VM image, or maybe a package from compiled code - you declare that you will never ever change it. Often if any changes are required, you declare that a new version of \"thing\" will be created instead.</li> </ul>"},{"location":"docs/interview-questions/sre/sre/#recommended-resources","title":"Recommended Resources","text":""},{"location":"docs/interview-questions/sre/sre/#courses","title":"Courses","text":"<ul> <li>https://kodekloud.com/</li> </ul>"},{"location":"docs/interview-questions/sre/sre/#articles","title":"Articles","text":"<ul> <li>https://roadmap.sh/devops</li> <li>https://www.srepath.com/site-reliability-engineering-glossary/</li> </ul>"},{"location":"docs/interview-questions/sre/sre/#books","title":"Books","text":"<ul> <li>https://www.amazon.com/Practice-Cloud-System-Administration-Practices/dp/032194318X</li> <li>https://sre.google/books/</li> <li>https://www.amazon.com/Accelerate-Software-Performing-Technology-Organizations/dp/1942788339</li> <li>https://www.amazon.com/Phoenix-Project-DevOps-Helping-Business/dp/0988262592</li> </ul>"},{"location":"docs/interview-questions/sre/sre/#references","title":"References","text":"<ul> <li>https://www.interviewbit.com/ansible-interview-questions/</li> <li>https://www.simplilearn.com/tutorials/kubernetes-tutorial?source=sl_frs_nav_playlist_video_clicked</li> <li>https://www.simplilearn.com/terraform-interview-questions-and-answers-article</li> <li>https://www.interviewbit.com/docker-interview-questions/</li> </ul>"},{"location":"docs/interview-questions/terraform/scenarios/","title":"Terraform Scenarios","text":"<p>This scenario is intended to walk you through the general process of how to use terraform.</p>"},{"location":"docs/interview-questions/terraform/scenarios/#what-are-the-first-steps-for-working-with-terraform","title":"What are the first steps for working with Terraform","text":"<ol> <li>Download/write the terraform code</li> <li>Run <code>terraform init</code> to download the state and providers for the code</li> </ol>"},{"location":"docs/interview-questions/terraform/scenarios/#what-are-the-main-files-for-working-with-terraform","title":"What are the main files for working with Terraform","text":"<ol> <li>Typically main.tf, variables.tf, outputs.tf, providers.tf are the most commonly used. As well as any .tfvars files that provide the values for variables, and the terraform.tfstate that contains the state</li> </ol>"},{"location":"docs/interview-questions/terraform/scenarios/#how-would-you-apply-your-terraform-code","title":"How would you apply your Terraform code?","text":"<ol> <li>First you would open a terminal and ensure that it's in the same directory as your code.</li> <li>Run <code>terraform init</code> to download providers and terraform state</li> <li>You can perform a <code>terraform validate</code> to make sure the code will \"compile\" or interpolate correctly, but not required</li> <li>Perform a <code>terraform plan</code> to show the planned changes for your code</li> <li>Run <code>terraform apply</code> and type <code>yes</code> to apply the changes</li> </ol>"},{"location":"docs/interview-questions/terraform/terraform/","title":"Terraform","text":"<ul> <li>Terraform</li> <li>Can you explain what Infrastructure as Code and why its important</li> <li>Whats the first command you run when start a terraform project</li> <li>What are the most useful Terraform commands?</li> <li>What is the terraform state file and why is it important</li> <li>How would you store your terraform state</li> <li>What is a terraform backend</li> <li>What is State File Locking?</li> </ul>"},{"location":"docs/interview-questions/terraform/terraform/#can-you-explain-what-infrastructure-as-code-and-why-its-important","title":"Can you explain what Infrastructure as Code and why its important","text":"<ul> <li>Infrastructure as Code or IaC is a process that DevOps teams should follow to have a more organized way of managing the infra. Instead of some throwaway scripts or manually configuring any cloud component, there should be a code repo where all of these will lie and any change in configuration should be done through it. It is wise to put it under source control also. This improves speed, consistency, and accountability.</li> </ul>"},{"location":"docs/interview-questions/terraform/terraform/#whats-the-first-command-you-run-when-start-a-terraform-project","title":"Whats the first command you run when start a terraform project","text":"<ul> <li>terraform init to download the state and any providers</li> </ul>"},{"location":"docs/interview-questions/terraform/terraform/#what-are-the-most-useful-terraform-commands","title":"What are the most useful Terraform commands?","text":"<ul> <li><code>terraform init</code> - initializes the current directory</li> <li><code>terraform refresh</code> - refreshes the state file</li> <li><code>terraform output</code> - views Terraform outputs</li> <li><code>terraform apply</code> - applies the Terraform code and builds stuff</li> <li><code>terraform destroy</code> - destroys what has been built by Terraform</li> <li><code>terraform graph</code> - creates a DOT-formatted graph</li> <li><code>terraform plan</code> - a dry run to see what Terraform will do</li> </ul>"},{"location":"docs/interview-questions/terraform/terraform/#what-is-the-terraform-state-file-and-why-is-it-important","title":"What is the terraform state file and why is it important","text":"<ul> <li>Terraform must store state about your managed infrastructure and configuration. This state is used by Terraform to map real world resources to your configuration, keep track of metadata, and to improve performance for large infrastructures. This state is stored by default in a local file named \"terraform.tfstate\".</li> <li>This is how terraform knows what actions to perform</li> </ul>"},{"location":"docs/interview-questions/terraform/terraform/#how-would-you-store-your-terraform-state","title":"How would you store your terraform state","text":"<ul> <li>You can store your terraform state in the local repository by default, but you should store it somewhere remotely like a backend or github (not for prod)</li> </ul>"},{"location":"docs/interview-questions/terraform/terraform/#what-is-a-terraform-backend","title":"What is a terraform backend","text":"<ul> <li>Each Terraform configuration can specify a backend, which defines two main things:</li> <li>Where operations are performed (terraform cloud/enterprise)</li> <li>Where the state is stored</li> <li>Preferred backends are Terraform Cloud/Enterprise or Amazon S3 and DynamoDB</li> </ul>"},{"location":"docs/interview-questions/terraform/terraform/#what-is-state-file-locking","title":"What is State File Locking?","text":"<ul> <li>State file locking is Terraform mechanism in which operations on a specific state file are blocked to avoid conflicts between multiple users performing the same process. When one user releases the lock, then only the other one can operate on that state. This helps in preventing state file corruption. This is a backend operation.</li> </ul>"},{"location":"playbooks/discord-webhook/","title":"Add Discord Webhook","text":"<p>To create a Discord webhook, follow these steps:</p> <ol> <li>Open Discord and navigate to the server where you want to create the webhook.</li> <li>Click on the server settings menu (the gear icon next to the server name) and select \"Integrations\".</li> <li>Click on the \"Create Webhook\" button and enter a name for your webhook.</li> <li>Customize the avatar and username for your webhook if desired.</li> <li>Copy the webhook URL and save it for later use.</li> <li>Click on the \"Save\" button to create your webhook.</li> </ol> <p>You can now use the webhook URL to send messages to your Discord server from external applications or services.</p>"},{"location":"playbooks/find-large-files/","title":"Find Large Files Linux","text":"<p>To find large files on a Linux system, use the following command:</p> <pre><code>du -a /opt | sort -n -r | head -n 15 | numfmt --to=iec --format=\"%-5f\"\n</code></pre>"},{"location":"runbooks/Swap/","title":"Add Swap","text":"<p>The steps below will walk an operator through adding a 4gb swap space to a node</p>"},{"location":"runbooks/Swap/#steps","title":"Steps","text":"<ol> <li>Run <code>fallocate -l 4G /swapfile</code></li> <li>Run <code>dd if=/dev/zero of=/swapfile bs=1024 count=4194304</code></li> <li>Run <code>chmod 600 /swapfile</code></li> <li>Run <code>mkswap /swapfile</code></li> <li>Run <code>swapon /swapfile</code></li> <li>Run <code>vim /etc/fstab</code></li> <li>Run <code>/swapfile swap swap defaults 0 0</code></li> </ol>"},{"location":"runbooks/argocd/","title":"Argocd","text":"<p>kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d</p>"},{"location":"runbooks/devcontainers/","title":"Devcontainers","text":"<p>Devcontainers are a feature of Visual Studio Code that enables developers to develop in a containerized environment. Here are the steps to get started with Devcontainers:</p> <ol> <li>Install Visual Studio Code</li> <li>Install the Remote Development extension</li> <li>Open a project in Visual Studio Code</li> <li>Click on the green \"&gt;&lt;\" icon in the bottom left corner of the window</li> <li>Select \"Remote-Containers: Reopen in Container\"</li> <li>Wait for the container to build and start</li> <li>Develop as usual within the container</li> </ol> <p>Devcontainers are useful because they enable developers to work in an isolated environment with all the necessary tools and dependencies pre-installed. This can be especially helpful when working with complex applications or in a team setting.</p>"},{"location":"runbooks/expand-disk/","title":"Expand Disk","text":"<ol> <li>Expand disk in vSphere</li> <li>Restart VM</li> <li>fdisk /dev/sda</li> <li>Enter <code>p</code> to print your initial partition table.</li> <li>Enter <code>d</code> (delete) followed by 2 to delete the existing partition definition (partition 1 is usually /boot and partition 2 is usually the root partition).</li> <li>Enter <code>n</code> (new) followed by p (primary) followed by 2 to re-create partition number 2 and enter to accept the start block and enter again to accept the end block which is defaulted to the end of the disk.</li> <li>Enter <code>p</code> to print your new partition table and make sure the start block matches what was in the initial partition table printed above.</li> <li>Enter <code>w</code> to write the partition table to disk. You will see an error about Device or resource busy which you can ignore.</li> <li><code>partx -a /dev/sda</code></li> <li><code>xfs_growfs /</code></li> </ol>"},{"location":"runbooks/gitlab/","title":"Gitlab","text":""},{"location":"runbooks/gitlab/#gotchas","title":"Gotchas","text":"<ol> <li>Multi-line variables must have <code>/n</code> for new lines and then have <code>echo -e $VAR</code> to interpolate them properly</li> </ol>"},{"location":"runbooks/gitlab/#setup-gitlab-runners","title":"Setup Gitlab Runners","text":"<ol> <li>Run <code>sudo vim /srv/gitlab-runner/config/config.toml</code> to edit the config file</li> <li> <p>Run the following to create a gitlab-runner</p> <p><code>sudo docker run -d --name gitlab-runner1 --restart always \\   -v /srv/gitlab-runner/config:/etc/gitlab-runner \\   -v /var/run/docker.sock:/var/run/docker.sock \\   gitlab/gitlab-runner:latest</code></p> </li> <li> <p>Run <code>sudo docker run --rm -it -v /srv/gitlab-runner/config:/etc/gitlab-runner gitlab/gitlab-runner register</code></p> </li> </ol>"},{"location":"runbooks/nfs/","title":"NFS Client Setup","text":"<p>Walks through how to connect to an NFS share</p>"},{"location":"runbooks/nfs/#requirements","title":"Requirements","text":"<ol> <li>Must have NFS client for Windows enabled to interact with the NFS server on truenas.lan</li> </ol>"},{"location":"runbooks/nfs/#steps","title":"Steps","text":"<ol> <li>Run <code>mount -o anon \\\\truenas.lan\\mnt\\Pool1 Z:</code></li> <li>Open regedit and edit <code>HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\ClientForNFS\\CurrentVersion\\Default</code></li> <li>Add New DWORD(32-bit) value inside of default for AnonymousUid and AnonymousGid</li> <li>Restart the your machine</li> <li>Run <code>mount -o nolock -o anon \\\\truenas.lan\\mnt\\Pool1\\NFS Z:</code></li> </ol>"},{"location":"runbooks/setup/","title":"Setup","text":""},{"location":"runbooks/setup/#install-ansible","title":"Install Ansible","text":"<p>Steps for installing ansible</p> <pre><code>sudo apt install -y software-properties-common\nsudo add-apt-repository --yes --update ppa:ansible/ansible\nsudo apt update\nsudo apt install -y ansible\n</code></pre>"}]}